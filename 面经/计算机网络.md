## 说明

此笔记基本拷贝小林的《图解网络》用作自己的学习复盘，偶尔会增加一些《自顶向下》的原话

## HTTP

### HTTP是什么

HTTP 是超⽂本传输协议，也就是HyperText Transfer Protocol。

我们先来理解「⽂本」，在互联⽹早期的时候只是简单的字符⽂字，但现在「⽂本」的涵义已经可以扩展为图⽚、 视频、压缩包等，在 HTTP 眼⾥这些都算作「⽂本」。 再来理解「超⽂本」，它就是超越了普通⽂本的⽂本，它是⽂字、图⽚、视频等的混合体，最关键有超链接，能从 ⼀个超⽂本跳转到另外⼀个超⽂本。

### HTTP常见的状态码

![image-20220324231744564](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220324231744564.png)



### HTTP常见字段有哪些

- `Host`字段：

  - 客户端发送请求时，⽤来指定服务器的域名

  - ```c++
    Host: www.A.com
    ```

- `Content-Length`字段：

  - 服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据⻓度

  - ```c++
    Content-Length: 1000
    ```

- `Connection`字段：

  - 最常⽤于客户端要求服务器使⽤ TCP 持久连接，以便其他请求复⽤。
  - HTTP/1.1 版本的默认连接都是持久连接，但为了兼容⽼版本的 HTTP，需要指定 Connection ⾸部字段的值为 Keep-Alive 

- `Content-Type`字段：

  - `Content-Type`字段字段⽤于服务器回应时，告诉客户端，本次数据是什么格式

  - ```c++
    //上⾯的类型表明，发送的是⽹⻚，⽽且编码是UTF-8
    Content-Type: text/html; charset=utf-8 
    ```

- `Accept`字段：

  - 客户端请求的时候，可以使⽤ Accept 字段声明⾃⼰可以接受哪些数据格式。

- `Content-Encoding`字段

  - ```c++
    Content-Encoding: gzip
    ```

### GET和POST有什么区别

`Get `⽅法的含义是请求从服务器获取资源，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。

⽽ `POST` ⽅法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报⽂的 body ⾥
⽐如，你在我⽂章底部，敲⼊了留⾔后点击「提交」（暗示你们留⾔），浏览器就会执⾏⼀次 POST 请求，把你的 留⾔⽂字放进了报⽂ body ⾥，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。

### GET和POST方法都是安全和幂等的吗

### HTTP的优点

HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。

**简单** 

HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式，易于理解，降低了学 习和使⽤的⻔槛

**灵活和易于扩展**

HTTP协议⾥的各类请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定 义和扩充。 

同时 HTTP 由于是⼯作在应⽤层（ OSI 第七层），则它下层可以随意变化。 HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚⾄把 TCP 层换成了基于 UDP 的 QUIC

**应⽤⼴泛和跨平台**

### HTTP的缺点

HTTP 协议⾥有优缺点⼀体的双刃剑，分别是「⽆状态、明⽂传输」，同时还有⼀⼤缺点「不安全」

⽆状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的 负担，能够把更多的 CPU 和内存⽤来对外提供服务。 

⽆状态的坏处，既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。 例如登录->添加购物⻋->下单->结算->⽀付，这系列操作都要知道⽤户的身份才⾏。但服务器不知道这些请求是有 关联的，每次都要问⼀遍身份信息。 这样每操作⼀次，都要验证信息，这样的购物体验还能愉快吗？

对于⽆状态的问题，解法⽅案有很多种，其中⽐较简单的⽅式⽤ Cookie 技术。 Cookie 通过在请求和响应报⽂中写⼊ Cookie 信息来控制客户端的状态

**Cookie**

![image-20220324232726250](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220324232726250.png)

明⽂意味着在传输过程中的信息，是可⽅便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接⾁眼查看，为我们调试⼯作带了极⼤的便利性。

**HTTP ⽐较严᯿的缺点就是不安全**

- 通信使⽤明⽂（不加密），内容可能会被窃听。⽐如，账号信息容易泄漏，那你号没了。 
- 不验证通信⽅的身份，因此有可能遭遇伪装。⽐如，访问假的淘宝、拼多多，那你钱没了。 ⽆法证明报⽂的完整性，所以有可能已遭篡改。
- ⽐如，⽹⻚上植⼊垃圾⼴告，视觉污染，眼没了。
- HTTP 的安全问题，可以⽤ HTTPS 的⽅式解决，也就是通过引⼊ SSL/TLS 层，使得在安全上达到了极致

### HTTP/1.1的性能如何

HTTP 协议是基于 TCP/IP，并且使⽤了「请求 - 应答」的通信模式，所以性能的关键就在这两点⾥

**长连接**

早期 HTTP/1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），⽽且是 串⾏请求，做了⽆谓的 TCP 连接建⽴和断开，增加了通信开销。

为了解决上述 TCP 连接问题，HTTP/1.1 提出了⻓连接的通信⽅式，也叫持久连接。这种⽅式的好处在于减少了 TCP 连接的᯿复建⽴和断开所造成的额外开销，减轻了服务器端的负载。

持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态

![image-20220324232950368](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220324232950368.png)

**管道⽹络传输**

HTTP/1.1 采⽤了⻓连接的⽅式，这使得管道（pipeline）⽹络传输成为了可能。

 即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第 ⼆个请求出去，可以减少整体的响应时间。 

举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。

但是服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求。要是前⾯的回应特别慢，后⾯就会有许多请求 排队等着。这称为「队头堵塞」

**队头阻塞**

「请求 - 应答」的模式加剧了 HTTP 的性能问题。 

因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户端⼀直请求不到数据，这也就是「队头阻塞」。好⽐上班的路上塞⻋

### HTTP与HTTPS有哪些区别

1. HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。 
2. HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之 后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。 
3. HTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。 
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

![image-20220324234205664](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220324234205664.png)

### HTTPS解决了HTTP的哪些问题

- HTTPS 在 HTTP 与 TCP 层之间加⼊了 SSL/TLS 协议，可以很好的解决了上述的⻛险
  - 信息加密：交互信息⽆法被窃取，但你的号会因为「⾃身忘记」账号⽽没。
  - 校验机制：⽆法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾⼴告。 
  - 身份证书：证明淘宝是真的淘宝⽹，但你的钱还是会因为「剁⼿」⽽没。

### HTTPS是如何解决HTTP不安全问题的

- 混合加密的⽅式实现信息的机密性，解决了窃听的⻛险。 
- 摘要算法的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了 篡改的⻛险。 
- 将服务器公钥放⼊到数字证书中，解决了冒充的⻛险。

**混合加密**

HTTPS 采⽤的是对称加密和⾮对称加密结合的「混合加密」方式

- 在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。
- 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据

**摘要算法**

- 

**数字证书**

客户端先向服务器端索要公钥，然后⽤公钥加密信息，服务器收到密⽂后，⽤⾃⼰的私钥解密。 

这就存在些问题，如何保证公钥不被篡改和信任度？ 

所以这⾥就需要借助第三⽅权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

![image-20220324235043905](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220324235043905.png)

### HTTPS是如何建立连接的，期间交互了什么

**SSL/TLS 协议基本流程**

- 客户端向服务器索要并验证服务器的公钥。 
- 双⽅协商⽣产「会话秘钥」。
- 双⽅采⽤「会话秘钥」进⾏加密通信。

前两步也就是 SSL/TLS 的建⽴过程，也就是握⼿阶段。 SSL/TLS 的「握⼿阶段」涉及四次通信，可⻅下图：

![image-20220324235409060](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220324235409060.png)

![image-20220324235415180](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220324235415180.png)

**ClientHello**

- ⾸先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求
- 在这⼀步，客户端主要向服务器发送以下信息：
  - 客户端⽀持的 SSL/TLS 协议版本，如 TLS 1.2 版本。
  - 客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。
  - 客户端⽀持的密码套件列表，如 RSA 加密算法

**SeverHello**

- 服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：
  - 确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。
  - 服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。
  - 确认的密码套件列表，如 RSA 加密算法。
  - 服务器的数字证书。

### HTTPS/1.1 HTTP/2 HTTP/3的演变



## TCP/UDP

### TCP 三次握手与四次挥手

### TCP头部格式

![image-20220306205038392](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306205038392.png)

- 序列号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就 「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。 
- 确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数 据都已经被正常接收。用来解决不丢包的问题。 
- 控制位： 
  - ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须 设置为 1 。
  - RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。 
  - SYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。 
  - FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主 机之间就可以相互交换 FIN 位为 1 的 TCP 段。

### 为什么需要 TCP 协议？ TCP 工作在哪一层？

IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。

- 如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。 
- 因为 TCP 是一个工作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的

### 什么是 TCP ？

**TCP 是面向连接的、可靠的、基于字节流的传输层通信协议**

- 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一 对多是无法做到的； 
- 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 
- 字节流：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前 一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的 报文会自动丢弃。

### 如何唯一确定一个 TCP 连接呢？

**TCP 四元组可以唯一的确定一个连接**

四元组包括如下： 

- 源地址 
- 源端口 
- 目的地址 
- 目的端口

- 源地址和目的地址的字段（32位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。 
- 源端口和目的端口的字段（16位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。

### 有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？

> [单台服务器上的并发TCP连接数可以有多少？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/405798293)

服务器通常固定在某个本地端口上监听，等待客户端的连接请求。

![image-20220306211714408](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306211714408.png)

通常我们是固定在某个服务器端口上监听客户端连接，而TCP连接是一个四元组，现在我们的目标地址和目标端口是不变的，那么可变量就是客户端IP和客户端端口了，所以最大TCP连接数就是`客户端的IP数 * 客户端的端口数`

**当然，服务端最大并发 TCP 连接数远不能达到理论上限。** 

- 首先主要是文件描述符限制，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目； 
- 另一个是内存限制，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的。

### UDP 和 TCP 有什么区别呢？分别的应用场景是？

UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。 UDP 协议真的非常简，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：![image-20220306212851930](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306212851930.png)

- 目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。
-  包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。 
- 校验和：校验和是为了提供可靠的 UDP 首部和数据而设计

### TCP三次握手

![image-20220306213043368](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306213043368.png)

- 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态
- 客户端会随机初始化序号（ client_isn ），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态
- 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（ server_isn ），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1 , 接着把 SYN 和 ACK 标志位置为 1 。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到 服务器的数据，之后客户端处于 ESTABLISHED 状态。 
- 服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。
- 从上面的过程可以发现第三次握⼿是可以携带数据的，前两次握⼿是不可以携带数据的
- 一旦完成三次握⼿，双方都处于 ESTABLISHED 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数 据了

### 为什么需要三次握手

#### **避免历史连接**

客户端接收到服务器端给自己的回应报文，会检查此报文的`ACK NUMBER`是否是自己期望的值，即`server_isn + 1`，如果不是，则发起`RST`报文终止连接

如果是两次握手，就不会有这个判断，可能被历史连接所干扰

**客户端连续发送多次 SYN 建立连接的报文，在网络拥堵情况下**：

-  一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端； 
- 那么此时服务端就会回一个 SYN + ACK 报文给客户端； 
- 客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 RST 报文给服务端，表示中止这一次连接。

#### 同步双方序列号

在自顶向下里面讲过，序列号可以让对方知道这是否是一个重复的数据，然后抛弃掉。所以序列号很重要，需要同步。

**序列号作用**

- 接收方可以去除重复的数据； 
- 接收方可以根据数据包的序列号按序接收； （中间缺了一段数据怎么办，根据序列号继续返回该`ACK`，然后最后得到该数据，然后补上，获得连续的一串数据）
- 可以标识发送出去的数据包中， 哪些是已经被对方收到的

#### 避免资源浪费

如果只有「两次握⼿」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握⼿，服务器不清楚客户端是否收到了自己发送的建立连接的 ACK 确认信号，所以每收 到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？

即两次握⼿会造成消息滞留情况下，服务器重复接受无用的连接请求 SYN 报文，而造成重复分配资源。

其实跟之前的第一种情况差不多

### 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？![image-20220306215537640](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306215537640.png)

MTU ：一个网络包的最大长度，以太网中一般为 1500 字节；

MSS ：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度

**IP层分片情况**

当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成 若⼲片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后， 再交给上一层 TCP 传输层。 **这看起来井然有序，但这存在隐患的，那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。**

因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时重传。当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时 后，就会重发「整个 TCP 报文（头部 + 数据）」。 **因此，可以得知由 IP 层进行分片传输，是非常没有效率的**

**TCP层分片**

所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分⽚，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分⽚了。 

经过 TCP 层分⽚后，如果一个 TCP 分⽚丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分⽚，大大 增加了重传的效率

### SYN攻击

假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一 个 SYN 报文，就进入 SYN_RCVD 状态，**但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务**

**避免方式**

其中⼀种解决⽅式是通过修改 Linux 内核参数，控制队列⼤⼩和当队列满时应做什么处理。

- 当⽹卡接收数据包的速度⼤于内核处理的速度时，会有⼀个队列保存这些数据包。控制该队列的最⼤值如下参数：

```c++
net.core.netdev_max_backlog
```

- SYN_RCVD 状态连接的最⼤个数：

```c++
net.ipv4.tcp_max_syn_backlog
```

- 超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：

```c++
net.ipv4.tcp_abort_on_overflow
```

避免 SYN 攻击⽅式⼆

![image-20220326171213745](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220326171213745.png)

- 当服务端接收到客户端的 SYN 报⽂时，会将其加⼊到内核的「 SYN 队列」； 
- 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报⽂； 
- 服务端接收到 ACK 报⽂后，从「 SYN 队列」移除放⼊到「 Accept 队列」； 
- 应⽤通过调⽤ accpet() socket 接⼝，从「 Accept 队列」取出连接

![image-20220326171327105](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220326171327105.png)

**如果应⽤程序过慢时，就会导致「 Accept 队列」被占满。**

![image-20220326171337393](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220326171337393.png)

如果不断受到 SYN 攻击，就会导致「 SYN 队列」被占满

tcp_syncookies 的⽅式可以应对 SYN 攻击的⽅法

![image-20220326171410845](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220326171410845.png)

- 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进⼊「 SYN 队列」； 
- 计算出⼀个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，
-  服务端接收到客户端的应答报⽂时，服务器会检查这个 ACK 包的合法性。如果合法，直接放⼊到「 Accept 队 列」。 最
- 后应⽤通过调⽤ accpet() socket 接⼝，从「 Accept 队列」取出的连接。

### TCP四次挥手

![image-20220306221846056](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306221846056.png)



- 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户 端进入 FIN_WAIT_1 状态。 
- 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。 
- 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 
- 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 
- 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 
- 服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，⾄此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSED 状态，⾄此客户端也完成连接的关闭

你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥⼿。 

这⾥一点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态

### 为什么要四次挥手

**就是因为还要等服务器处理完数据所以多了一次服务器向客户端发ACK的过程**

- 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。
-  服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服 务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。

### 为什么 TIME_WAIT 等待的时间是 2MSL？

MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路 由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。**所以 MSL 应该要大于等于 TTL 消耗为 0 的 时间，以确保报文已被自然消亡**

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： **网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。**

2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没 有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时

### 为什么需要 TIME_WAIT 状态

主动发起关闭连接的一方，才会有 TIME-WAIT 状态。

 需要 TIME-WAIT 状态，主要是两个原因： 

- 防止具有相同「四元组」的「旧」数据包被收到； 
- 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关 闭

**防止具有相同「四元组」的「旧」数据包被收到； **

正常发送的时候有数据包因为网络延迟了，然后直到结束都没有到达，等到这个TCP四元组又一次建立连接的时候，上面那个数据包来了。这样子就会被上个连接的数据包所干扰。所以需要等待`2MSL`，这段时间足够报文被丢弃了

**原因⼆：保证连接正确关闭**

![image-20220306223623514](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306223623514.png)

- 如上图红⾊框框客户端四次挥⼿的最后一个 ACK 报文如果在网络中被丢失了，**此时如果客户端 TIME-WAIT 过短或没有，则就直接进入了 CLOSED 状态了，那么服务端则会一直处在 LASE_ACK 状态**。
- 当客户端发起建立连接的 SYN 请求报文后，服务端会发送 RST 报文给客户端，连接建立的过程就会被终止

### TIME_WAIT 过多有什么危害

- 第一是内存资源占用； 
- 第⼆是对端口资源的占用，一个 TCP 连接⾄少消耗一个本地端口

**如果发起连接一方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。**

**客户端受端口资源限制：** 

- 客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接。 

**服务端受系统资源限制：** 

- 由于一个四元组表示 TCP 连接，理论上服务端可以建立很多连接，**服务端确实只监听一个端口 但是会把连接 扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。所以当 服务端出现大重 TIME_WAIT 时，系统资源被占满时，会导致处理不过来新的连接。**

### 如何优化 TIME_WAIT？

过多的 TIME-WAIT 状态主要的危害有两种：

- 第⼀是内存资源占⽤； 
- 第⼆是对端⼝资源的占⽤，⼀个 TCP 连接⾄少消耗⼀个本地端⼝

第⼆个危害是会造成严᯿的后果的，要知道，端⼝资源也是有限的，⼀般可以开启的端⼝为 32768～61000 ，也可 以通过如下参数设置指定

这⾥给出优化 TIME-WAIT 的⼏个⽅式，都是有利有弊

- 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项； 
- net.ipv4.tcp_max_tw_buckets 
- 程序中使⽤ SO_LINGER ，应⽤强制使⽤ RST 关闭。

```c++

```



### TCP 重传、滑动窗口、流量控制、拥塞控制

#### TCP重传

但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？ 所以 TCP 针对数据包丢失的情况，会用重传机制解决。

**超时重传**

重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确 认应答报文，就会重发该数据，也就是我们常说的超时重传。

TCP 会在以下两种情况发生超时重传： 数据包丢失、确认应答丢失

![image-20220306225756145](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306225756145.png)

**超时重传时间设置**

`RTT` 就是数据从网络一端传送到另一端所需的时间，也就是包的往返时间。

超时重传时间是以` RTO （Retransmission Timeout 超时重传时间）`表示

![image-20220306230754863](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306230754863.png)

- 当超时时间 RTO 较大时，重发就慢，丢了⽼半天才重发，没有效率，性能差； 
- 当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超 时，更多的超时导致更多的重发

根据上述的两种情况，我们可以得知，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。

**如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是超时间隔加倍**。 

也就是每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。**两次超时，就说明网络环境差，不宜频繁反复发送**

**快速重传**

快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段

<img src="https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220307105142845.png" alt="image-20220307105142845" style="zoom:80%;" />

但是它依然面临着另外一个问题。就是重传的时候，是重传之前的一个，还是重传所有的问题？

根据 TCP 不同的实现，以上两种情况都是有可能的。可见，这是一把双刃剑。 为了解决不知道该重传哪些 TCP 报文，于是就有 SACK 方法。

**SACK方法**

这种方式需要在 TCP 头部「选项」字段⾥加一个 SACK 的东⻄，**它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。** 

如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 SACK 信息发现只有 200~299 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。

![image-20220306232437410](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306232437410.png)

如果要⽀持 SACK ，必须双方都要⽀持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux 2.4 后默认打开）

**D-SACK**

Duplicate SACK 又称 D-SACK ，**其主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

![image-20220307111004505](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220307111004505.png)

- 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499） 
- 于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500，告诉「发送方」 3000~3500 的 数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 D-SACK 。 
- 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报⽂丢了。

#### 滑动窗口

我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。 这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。

![image-20220306234036711](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306234036711.png)

为解决这个问题，TCP 引入了窗口这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。 那么有了窗口，就可以指定窗口大小，**窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。**

**窗口的实现实际上是操作系统开辟的一个缓存空间**，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。**如果按期收到确认应答，此时数据就可以从缓存区清除。**

![image-20220306234119955](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306234119955.png)

> 窗口大小由哪一方决定

TCP 头⾥有一个字段叫 Window ，也就是窗口大小

这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来 发送数据，而不会导致接收端处理不过来。 所以，通常窗口的大小是由接收方的窗口大小来决定的。

**发送方的滑动窗口**

![image-20220306234146482](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220306234146482.png)

- 已发送并收到`ACK`确认的数据
- 已发送但未收到`ACK`确认的字段
- 未发送但总大小仍在接收方处理范围内
- 未发送但总大小超过接收方处理范围

**接收方的滑动窗口**

![image-20220307111444406](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220307111444406.png)

- RCV.WND ：表示接收窗口的大小，它会通告给发送方。 
- RCV.NXT ：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。 
- 指向 #4 的第一个字节是个相对指针，它需要 RCV.NXT 指针加上 RCV.WND 大小的偏移量，就可以指向 #4 的 第一个字节了。

#### 流量控制

发送方不能无脑的发数据给接收方，要考虑接收方处理能力。 如**果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流重的无端的浪费**。 为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量， 这就是所谓的流量控制。

>  操作系统缓冲区与滑动窗口的关系

我们假定了发送窗口和接收窗口是不变的，**但是实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会被操作系统调整**

- 客户端发送 140 字节数据后，可用窗口变为 220 （360 - 140）。 
- 服务端收到 140 字节数据，但是服务端非常繁忙，应用进程只读取了 40 个字节，还有 100 字节占用着缓冲区，于是接收窗口收缩到了 260 （360 - 100），最后发送确认信息时，将窗口大小通告给客户端。
- 客户端收到确认和窗口通告报⽂后，发送窗口减少为 260。
- 客户端发送 180 字节数据，此时可用窗口减少到 80。
- 服务端收到 180 字节数据，但是应用程序没有读取任何数据，这 180 字节直接就留在了缓冲区，于是接收窗 口收缩到了 80 （260 - 180），并在发送确认信息时，通过窗口大小给客户端。
-  客户端收到确认和窗口通告报⽂后，发送窗口减少为 80。
- 客户端发送 80 字节数据后，可用窗口耗尽。 
- 服务端收到 80 字节数据，但是应用程序依然没有读取任何数据，这 80 字节留在了缓冲区，于是接收窗口收缩 到了 0，并在发送确认信息时，通过窗口大小给客户端。
- 客户端收到确认和窗口通告报⽂后，发送窗口减少为 0。

> 如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。

为了防止这种情况发生，**TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。**

> 窗口关闭（可能造成死锁情况，需要定时器（持续定时器））

![image-20220307115205487](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220307115205487.png)

为了解决这个问题，TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持 续计时器。 

如果持续计时器超时，就会发送窗口探测 ( Window probe ) 报⽂，而对方在确认这个探测报⽂时，给出自己现在的接收窗口大小。

> 糊涂窗口综合症

如果接收方太忙了，来不及取走接收窗口⾥的数据，那么就会导致发送方的发送窗口越来越小。 

到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节， 这就是糊涂窗口综合症

要知道，我们的 TCP + IP 头有 40 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济 了。 就好像一个可以承载 50 人的大巴车，每次来了一两个人，就直接发车。除非家⾥有矿的大巴司机，才敢这样玩， 不然迟早破产。

要解决这个问题也不难，大巴司机等乘客数量超过了 25 个，才认定可以发车。 现举个糊涂窗口综合症的栗⼦，考虑以下场景： 接收方的窗口大小是 360 字节，但接收方由于某些原因陷入困境，假设接收方的应用层读取的能力如下： 接收方每接收 3 个字节，应用程序就只能从缓冲区中读取 1 个字节的数据； 在下一个发送方的 TCP 段到达之前，应用程序还从缓冲区中读取了 40 个额外的字节

**所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：** 

- 接收方可以通告一个小的窗口 
- 而发送方可以发送小数据 

**于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了** 

- 让接收方不通告小窗口给发送方 
- 让发送方避免发送小数据

> 怎么让接收方不通告小窗口呢

当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 0 ，也就阻止了发送方再发数据过来。 

等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发 送方发送数据过来。

> 怎么让发送方避免发送小数据呢？

发送方通常的策略: 使用 **Nagle** 算法，该算法的思路是延时处理，它满⾜以下两个条件中的一条才可以发送数据： 

- 要等到窗口大小 >= MSS 或是 数据大小 >= MSS 
- 收到之前发送数据的 ack 回包 只要没满⾜上面条件中的一条，发送方一直在囤积数据，直到满⾜上面的发送条件

#### 拥塞控制

前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。

 一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

 **在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....**

所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。 于是，就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。 

为了在「发送方」调节所要发送数据的量，定义了一个叫做「拥塞窗口」的概念。

> 什么是拥塞窗口？和发送窗口有什么关系呢？

**拥塞窗口 cwnd是发送方维护的一个的状态变量**，它会根据网络的拥塞程度动态变化的。

 我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。

拥塞窗口 cwnd 变化的规则：

- 只要网络中没有出现拥塞， cwnd 就会增大；
- 但网络中出现了拥塞， cwnd 就减少；

> 怎么知道当前网络是否出现了拥塞呢？

其实只要「发送方」没有在规定时间内接收到 ACK 应答报⽂，也就是发生了超时重传，就会认为网络出现了用拥塞

> 拥塞控制有哪些控制算法？

拥塞控制主要是四个算法：

- 慢启动 
- 拥塞避免 
- 拥塞发生 
- 快速恢复

**慢启动**

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提⾼发送数据包的数量， 如果一上来就发大量的数据，这不是给网络添堵吗？

**慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1**

这⾥假定拥塞窗口 cwnd 和发送窗口 swnd 相等，下面举个栗⼦： 

- 连接建立完成后，一开始初始化 cwnd = 1 ，表示可以传一个 MSS 大小的数据。 
- 当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个 
- 当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个 
- 当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。

![image-20220307122204948](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220307122204948.png)

> 那慢启动涨到什么时候是个头呢？

有一个叫慢启动⻔限 ssthresh （slow start threshold）状态变量。 

- 当 cwnd < ssthresh 时，使用慢启动算法。 
- 当 cwnd >= ssthresh 时，就会使用「拥塞避免算法」。
- 一般来说 ssthresh 的大小是 65535 字节

**拥塞避免算法**

那么进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1/cwnd。 

接上前面的慢启动的栗⼦，现假定 ssthresh 为 8 

- 当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据， **变成了线性增长。**

![image-20220307122451308](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220307122451308.png)

所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。

**拥塞发生**

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种： 

- 超时重传 
- 快速重传 

这两种使用的拥塞发送算法是不同的，接下来分别来说说

> 发生超时重传的拥塞发生算法

当发生了「超时重传」，则就会使用拥塞发生算法。 这个时候，ssthresh 和 cwnd 的值会发生变化： 

- ssthresh 设为 cwnd/2 
- cwnd 重置为 1

![image-20220307122821336](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220307122821336.png)

接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种 方式太激进了，反应也很强烈，会造成网络卡顿

> 发生快速重传的拥塞发生算法

还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传

**TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分** ，则 ssthresh 和 cwnd 变化如下

- cwnd = cwnd/2 ，也就是设置为原来的一半; 
- ssthresh = cwnd ; 
- 进入快速恢复算法

**快速恢复**

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟 糕，所以没有必要像 RTO 超时那么强烈

正如前面所说，进入快速恢复之前， cwnd 和 ssthresh 已被更新了：

- cwnd = cwnd/2 ，也就是设置为原来的一半;
- ssthresh = cwnd ;

然后，进入快速恢复算法如下：

- 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）； 
- 重传丢失的数据包； 
- 如果再收到重复的 ACK，那么 cwnd 增加 1； 
- 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入 拥塞避免状态

![image-20220307123022233](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220307123022233.png)

也就是没有像「超时重传」一夜回到解放前，而是还在比较⾼的值，后续呈线性增长

## IP

