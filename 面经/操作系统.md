## 操作系统内存管理

> [(83 封私信 / 83 条消息) 内存为什么要分页？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/436136392)

### 早期无存储器抽象

早期是`CPU`直接操作内存的物理地址，无法运行两个及以上程序。第二个程序会覆盖掉第一个程序在物理地址上写入的值，导致程序崩溃。

后来为了运行多个程序，`IBM360`早期模型将内存分成不同的块，每个块分一个`4`位的保护键。一个运行中的进程如果访问保护键与其程序状态字不同的内存，那么这个事件就会被硬件捕获。这样可以防止用户进程之间、用户进程和操作系统之间的干扰。

**但是还是直接操纵物理地址，有一些`jmp`指令可能跳到了别的程序的地盘，造成错误访问，所以我们需要每个进程都有自己的一套地址空间**

### **存储器抽象：地址空间**

- 我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address） 
- 实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）

进程持有的虚拟地址会通过  **CPU 芯片中的内存管理单元（MMU）** 的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示

![image-20220305104518281](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305104518281.png)

### **内存分段**

分段机制下的虚拟地址由两部分组成，段选择子和段内偏移量

- 分段也有虚拟地址的概念，比如 `访问 30 = 访问 基址地址 + 30`，不过物理地址上是连续的；
- 而后面的页操作是在虚拟内存分配连续的地址然后再通过映射手段，映射到不连续的物理地址上

![image-20220305104552271](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305104552271.png)



- 我们直接将每个进程的地址空间映射到物理内存的不同部分，）
- 程序装载到内存中 **连续的** 空闲位置且装载期间无需重定位。
- 当一个程序运行时，程序的起始物理地址装载到基址寄存器中，程序的长度装载到界限寄存器中

**使用基址寄存器的缺点**

- 每次访问内存都需要进行加法和比较运算，会很慢
- 会有内存碎片（在物理地址上分配连续的空间，所以会导致有些不能利用的内存碎片出现，这些内存太小了，并且我们需要连续的一大片，不能随机取过来使用）

**交换技术**

之前的基址寄存器和界限寄存器避免了进程间访问同一物理内存的错误，通过重定位使进程都在各自的内存空间内运行。但是，我们的内存真的有这么大可以容纳所有的进程吗？显然，这点内存是不够的

有两种处理内存超载的通用方法

- 交换技术：把一个进程完整调入内存，使该进程运行一段事件，然后把它存回磁盘。空闲进程主要储存在磁盘上，所以不运行时就不会占用内存。
- 虚拟内存技术：该策略使程序在只有一部分被调入内存的情况下运行

**内存碎片**

- 外部内存碎片，也就是产⽣了多个不连续的小物理内存，导致新的程序无法被装载；（分段操作产生的）
- 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；

### **内存分页**

分段的好处就是能产⽣连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。**交换技术不够用，于是又有了虚拟内存分页**

**虚拟内存使得整个地址空间可以用较小的单元映射到物理内存，而不是为正文段和数据段分别进行重定位**

分页是把整个虚拟和物理内存空间切成一段段固定尺⼨的大小。这样一个连续并且尺⼨固定的内存空间， 我们叫页（Page）。在 Linux 下，每一页的大小为 4KB 。

![image-20220305133312615](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305133312615.png)

- 页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的⼯作。 
- ⽽当进程访问的虚拟地址在页表中查不到时，系统会产⽣一个缺页异常，进⼊系统内核空间分配物理内 存、更新进程页表，最后再返回用户空间，恢复进程的运行

### 分页是怎么解决分段的内存碎片、内存交换效率低的问题？

由于内存空间都是预先划分好的，也就不会像分段会产⽣间隙⾮常小的内存，这正是分段会产⽣内存碎片 的原因。⽽采用了分页，那么释放的内存都是以页为单位释放的，也就不会产⽣⽆法给进程使用的小内存

**连续性：程序可以使用一系列相邻连续的虚拟地址来映射物理内存中不连续的大内存缓冲区，所以不会产生内存碎片，因为对于物理内存来说并不是连续的，中间的内存也是有固定大小的，是可以被映射然后利用的**

### MMU是如何工作的

MMU通过**页表**这个工具将虚拟地址转换为物理地址。32位的虚拟地址分成两部分（虚拟页号和偏移量），MMU通过页表找到了虚拟页号对应的物理页号，物理页号+偏移量就是实际的物理地址。

### 简单分页缺点

因为操作系统是可以同时运行⾮常多的进程的，那这不就意味着页表会⾮常的庞大。 

在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。 

那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是⾮常大的内存了，更别说 64 位的环 境了

要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决⽅案。

### 多级页表

![image-20220305145432841](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305145432841.png)

**多级页表是如何解决占用内存过大的问题的**

每个进程都有 4GB 的虚拟地址空间，⽽显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为 会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问 的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。 

如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被 用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计 算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB ，这对⽐单级页表的 4MB 是不是一个巨大的节约？ 

那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的 职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能⼯作 了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，⽽二级分 页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）

### TLB

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的⼯序，这显然就降 低了这俩地址转换的速度，也就是带来了时间上的开销。

把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们， 就在 CPU 芯片中，加⼊了一个专⻔存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB （Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。

![image-20220305150442345](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305150442345.png)

### 段页式内存管理

**段页式内存管理实现的⽅式：** 

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
- 地址结构就由段号、段内页号和页内位移三部分组成。

**地址结构就由段号、段内页号和页内位移三部分组成。**

- 第一次访问段表，得到页表起始地址； 
- 第二次访问页表，得到物理页号； 
- 第三次将物理页号与页内位移组合，得到物理地址。

可用软、硬件相结合的⽅法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提⾼了内存的 利用率。

## 进程和线程

### 进程和线程的区别和联系

- 进程是**用某种方法将相关的资源集中在一起的一种抽象**。进程有存放程序正文和数据以及其他资源的地址空间，这些资源中有打开的文件，子进程，定时器，信号处理程序等。我们让进程对他们进行管理
- 另一个概念，进程中有一个用于执行的线程，线程中有程序计数器，用来记录执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还有一个堆栈，用来记录执行历史。**线程是在`CPU`上被调度执行的实体**

**自己的话**

- 进程是操作系统进行资源分配基本单位，我们说一个运行起来的程序叫做进程，它运行需要内存（地址空间），需要程序计数器，需要CPU支持，所以它需要利用系统的种种资源，所以我们称它为资源分配的基本单位。
- 线程则是`CPU`上被调度执行的实体，是程序执行的最小单位）；线程可以完成某个子任务，`CPU`执行指令需要程序计数器，所以线程有程序计数器，寄存器，堆栈。
- 一个进程可以有多个线程，但是一个线程只能属于一个进程。
- 进程的创建需要系统分配内存和CPU，文件句柄等资源，销毁时也要进行相应的回收，所以进程的管理开销很大；但是线程的管理开销则很小。
- 进程之间不会相互影响；而一个线程崩溃会导致进程崩溃，从而影响同个进程里面的其他线程。

### 同一个进程内的线程共享什么资源

- 共享相同地址空间
- 共享全局变量
- 共享打开的文件
- 共享代码段

**但是寄存器和栈还有程序计数器是独立的**

### 进程状态

进程的状态

- 运行态（该时刻进程占用`CPU`）
- 就绪态（可运行，但是其他进程占据`CPU`）
- 阻塞态（不可运行，即使该进程占据`CPU`）

另外两个基本状态

- 创建状态（new）：进程正在被创建时的状态； 
- 结束状态（Exit）：进程正在从系统中消失时的状态

![image-20220223224226886](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220223224226886.png)

- **转换一**

进程可以执行`pause`系统调用阻塞进程，从而使该进程进入阻塞状态。或者当一个进程要从管道中读取数据，但是管道内无数据时，也会被阻塞

- **转换二和转换三**

这是由调度程序引起的，系统认为一个运行进程占用`CPU`时间足够了，就会让其他进程占用`CPU`，这会发生`转换二`。而其他进程也占用`CPU`到达时限了，系统又会将`CPU`给会原来进程使用，这时发生`转换三`

- **转换四**

当进程等来一个外部事件发生时（比如一些输入到达），则发生转换四，如果此时没有其它进程运行，则会立即触发转换三，该进程运行

![image-20220305091238319](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305091238319.png)

### 线程模型

**用户线程**

- 在用户空间实现的线程，由用户态的线程库来完成对线程的管理
- 进程内设置有线程控制块记录创建的线程情况（线程表）
- 对于内核而言，它看不到用户级别的线程，而只能看到这个进程。

**优点**

- 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指 针、寄存器），TCB 由用户级线程库函数来维护，可用于不⽀持线程技术的操作系统；
-  用户线程的切换也是由线程库函数来完成的，⽆需用户态与内核态的切换，所以速度特别快；

**缺点**

- 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都 不能执行了。 
- 当一个线程开始运行后，除⾮它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程⽆法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。 
- 由于时间片分配给进程，故与其他进程⽐，在多线程执行时，每个线程得到的时间片较少，执行会⽐ 较慢

**内核线程**

- 内核线程是由操作系统管理的，线程对应的 TCB ⾃然是放在操作系统里的，这样线程的创建、终⽌和管理 都是由操作系统负责
- 所有阻塞线程的调用都是以系统调用的形式实现，当然代价会更大。当一个线程阻塞，内核可以运行同一个进程中的另一个线程或者运行另一个进程中的线程

**优点**

- 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；
- 分配给线程，多线程的进程获得更多的 CPU 运行时间；

**缺点**

- 在⽀持内核线程的操作系统中，由内核来维护进程和线程的上下⽂信息，如 PCB 和 TCB； 
- 线程的创建、终⽌和切换都是通过系统调用的⽅式来进行，因此对于系统来说，系统开销⽐较大；（回收节省资源）

**轻量级进程**

- 轻量级进程（Light-weight process，LWP）**是内核⽀持的用户线程，一个进程可有一个或多个 LWP，每 个 LWP 是跟内核线程一对一映射的**，也就是 LWP 都是由一个内核线程⽀持。

在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：

- `1 : 1` ，即一个 LWP 对应 一个用户线程；
  - 优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP； 
  - 缺点：每一个用户线程，就产⽣一个内核线程，创建线程的开销较大
- `N : 1` ，即一个 LWP 对应多个用户线程； 
  - 优点：用户线程要开几个都没问题，且上下⽂切换发⽣用户空间，切换的效率较高； 
  - 缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的
- `M : N` ，即多个 LMP 对应多个用户线程
  - 优点：综合了前两种优点，大部分的线程上下⽂发⽣在用户空间，且多个线程⼜可以充分利用多核 CPU 的资源

### Linux理论上可以创建的进程数量，一个进程可以创建多少线程

**理论创建进程数量**

我们用`pid_t`来表示一个进程的`pid`，因此能表示的进程的范围一定不会超过`pid_t`类型的大小，`pid_t`实际上就是一个`short`类型变量。

```c++
sys/types.h:

//pid_t就是一个short类型变量，实际表示的是内核中的进程表的索引
typedef short pid_t; /* used for process ids */
```

`2的16次方 = 65536`这只是一个理论值，实际上，由于内存等系统资源的限制，根本不会同时有这么多的进程存在。

**理论创建线程数量**

**创建一个线程会占用多少内存，这取决于分配给线程的调用栈大小**，可以用`ulimit -s`命令来查看大小。

```c++
ulimit -s
8192	//10M
```

一个进程的虚拟内存是4G，在Linux32位平台下，内核分走了1G，留给用户用的只有3G，于是我们可以想到，创建一个线程占有了10M内存，总共有3G内存可以使用。于是可想而知，最多可以创建差不多300个左右的线程。

### 协程

最开始是非抢占式任务，但是如果有人写代码崩了，那么就一起崩，无法把CPU让出。后来防着这种情况，就变成了抢占式任务，操作系统防着大家，每个进程固定就给这么多时间片，运行结束就换人，有人代码写崩了，也可以换人。

后来，多线程普及。线程也做成了抢占式多任务，但是这会涉及到线程同步问题，大家商量锁，互斥等操作比较麻烦，这样子代码执行的任务逻辑比较复杂，不能向以前一样很顺畅的走下去。

此时，非抢占式多任务的好处就出来了：大家都一家人，都想齐心合力把事情做好；因此，当“我”事情没做完而且并不会耽误太久时，你们就应该等我；而一旦我事情做完了、或者需要等待网络信号/磁盘准备好时，“我”也会痛快的主动交出控制权。

这个做法，使得协作式多任务之间执行权的交接点极为明晰；那么只要逻辑考虑清楚了，锁就是完全没必要的——反正不会抢夺嘛，事情没告一段落我就不会交执行权；交执行权之前确保不存在“悬置的、未确定未提交的修改”，脏读脏写就杜绝了。

**因此，协程这个概念的提出，使得程序逻辑更为清晰，执行更加可控。**

**协程不能让OS知道自己的存在。**

**这是因为，OS并没有协程支持；如果你想让OS知道你的存在，那么它就会把你当线程调度——于是抢占式多任务就又回来了，“协程”这个“协”字就名不副实了。**

为什么说这个“无法在CPU上并行”的束缚恰恰是协程的优点呢？

因为它是协作式多任务，不存在执行绪紊乱的可能。

没错，每次执行中，协程之间的具体执行顺序可能千变万化；但**协程执行权切换**却**只会发生在用户明确放弃执行权之后**——比如你明确执行了yield语句时。

- 协程实质上是一种在用户空间实现的协作式多线程架构。
- [也来谈谈协程 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/147608872)

### 进程间通信方法

进程之间的通信方式主要有六种，包括**管道，信号量，消息队列，信号，共享内存，套接字**。

* 管道：
  * 管道是半双工的，双方需要通信的时候，需要建立两个管道。
  * 管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据：管道一端的进程顺序地将进程数据写入缓冲区，另一端的进程则顺序地读取数据，该缓冲区可以看做一个循环队列，读和写的位置都是自动增加的，一个数据只能被读一次，读出以后再缓冲区都不复存在了。
  * 当缓冲区读空或者写满时，有一定的规则控制相应的读进程或写进程是否进入等待队列，当空的缓冲区有新数据写入或慢的缓冲区有数据读出时，就唤醒等待队列中的进程继续读写。管道是最容易实现的
  * 匿名管道pipe和命名管道除了建立，打开，删除的方式不同外，其余都是一样的。匿名管道只允许有亲缘关系的进程之间通信，也就是父子进程之间的通信，命名管道允许具有非亲缘关系的进程间通信。
  * 管道的底层实现 https://segmentfault.com/a/1190000009528245
* 信号量（可以实现多进程互斥同步）：
  * **信号量初始化为`1`代表互斥**
    * 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后 信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
    *  若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已 被占用，因此进程 B 被阻塞。 **直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始 值 1**
  * **信号量初始化为`0`代表同步**
    * 假设A、B分别为生产者和消费者，**A进行V操作生产，B进行P操作消费**
    * 如果进程 B ⽐进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没⽣产数据，于是进程 B 就阻塞等待； 
    * 接着，当进程 A ⽣产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作 的进程 B； 最后，进程 B 被唤醒后，意味着进程 A 已经⽣产了数据，于是进程 B 就可以正常读取数据了。
  * 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。
  * 信号量只有等待和发送两种操作。等待(P(sv))就是将其值减一或者挂起进程，发送(V(sv))就是将其值加一或者将进程恢复运行。
* 信号：
  * 上面说的进程间通信，都是常规状态下的⼯作模式。**对于异常情况下的⼯作模式，就需要用「信号」的⽅ 式来通知进程**
  * **信号是进程间通信机制中唯一的异步通信机制（意味着内核管理），因为可以在任何时候发送信号给某一进程**，一旦有信号产 ⽣，我们就有下面这几种，用户进程对信号的处理⽅式。
    * 1.执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终⽌进 程的意思。
    * 2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发⽣时，我们就执行相应的信号处理函数。 
    * 3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用 进程⽆法捕捉和忽略的，即 SIGKILL 和 SEGSTOP ，它们用于在任何时候中断或结束某一进程
* 共享内存：
  * 消息队列的读取和写⼊的过程，都会有发⽣用户态与内核态之间的消息拷⻉过程。那共享内存的⽅式，就 很好的解决了这一问题
  * **共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，就像由malloc()分配的内存一样使用。**
  * 共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写⼊的东⻄， 另外一个进程⻢上就能看到了，都不需要拷⻉来拷⻉去，传来传去，大大提高了进程间通信的速度。
  * 一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取读出，从而实现了进程间的通信。共享内存的效率最高，缺点是没有提供同步机制，需要使用锁等其他机制进行同步。
* 消息队列：
  * 管道的通信⽅式是效率低的，因此管道不适合进程间频繁地交换数据
  * 消息队列的通信模式就可以解决。⽐如，A 进程要给 B 进程发送消息，**A 进程把数据放在 对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。**同理，B 进程要给 A 进 程发送消息也是如此
  * **消息队列是保存在内核中的消息链表**，在发送数据时，会分成一个一个独⽴的数据单元，也就是消 息体（数据块），消息体是用户⾃定义的数据类型，**消息的发送⽅和接收⽅要约定好消息体的数据类型， 所以每个消息体都是固定大小的存储块，不像管道是⽆格式的字节流数据。**如果进程从消息队列中读取了 消息体，内核就会把这个消息体删除
  * 消息队列⽣命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面 提到的匿名管道的⽣命周期，是随进程的创建而建⽴，随进程的结束而销毁。
  * **消息队列不适合⽐较大数据的传输**，因为在内核中每个消息体都有一个最大⻓度的限制，同时所有队列所 包含的全部消息体的总⻓度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB ， 它们以字节为单位，分别定义了一条消息的最大⻓度和一个队列的最大⻓度。
  *  **消息队列通信过程中，存在用户态与内核态之间的数据拷⻉开销，因为进程写⼊数据到内核中的消息队列 时，会发⽣从用户态拷⻉数据到内核态的过程**，同理另一进程读取内核中的消息数据时，会发⽣从内核态 拷⻉数据到用户态的过程
  * 消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。
  * 可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。
* 套接字：
  * 套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。

### 进程间调度方法

- **先来先服务算法**

  - 每次从就绪队列选择最先进⼊队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。

  **缺点**

  - 当一个⻓作业先运行了，那么后面的短作业等待的时间就会很⻓，不利于短作业。 FCFS 对⻓作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O **繁忙型作业的系统**

- **最短作业优先调度算法**

  - 它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量

  **缺点**

  - 这显然对⻓作业不利，很容易造成一种极端现象。 ⽐如，一个⻓作业在就绪队列等待运行，而这个就绪队列有⾮常多的短作业，那么就会使得⻓作业不断的往后推，周转时间变⻓，致使⻓作业⻓期不会被运行

- **高响应比优先调度算法**

  - 每次进行进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最高的进程投⼊运行，「响应 ⽐优先级」的计算公式

  ![image-20220304224237263](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220304224237263.png)

  **特点**

  - 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应⽐」就越高，这样短作业的 进程容易被选中运行；
  - 如果两个进程「要求的服务时间」相同时，「等待时间」越⻓，「响应⽐」就越高，这就兼顾到了⻓作业进程，因为进程的响应⽐可以随时间等待的增加而提高，当其等待时间⾜够⻓时，其响应⽐便可 以升到很高，从而获得运行的机会；

- **时间片轮转调度算法**

  - 每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行
  - 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进 程； 如果该进程在时间片结束前阻塞或结束，则 CPU ⽴即进行切换；

  **特点**

  - 如果时间片设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率； 
  - 如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓。

- **最高优先级调度算法**

  - 调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法

  **优先级可分为静态优先级和动态优先级**

  - 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
  - 动态优先级：根据进程的动态变化调整优先级，⽐如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程 的优先级。

  **该算法也有两种处理优先级高的方法，非抢占式和抢占式：** 

  - 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
  - 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

### 进程的执行过程

进程的执行需要经过三大步骤：编译，链接和装入。

* 编译：将源代码编译成若干模块
* 链接：将编译后的模块和所需要的库函数进行链接。链接包括三种形式：静态链接，装入时动态链接（将编译后的模块在链接时一边链接一边装入），运行时动态链接（在执行时才把需要的模块进行链接）
* 装入：将模块装入内存运行

### 死锁的产生和恢复

### 孤儿进程和僵尸进程

* 孤儿进程是父进程退出后它的子进程还在执行，这时候这些子进程就成为孤儿进程。孤儿进程会被init进程收养并完成状态收集。
* 僵尸进程是指子进程完成并退出后父进程没有使用wait()或者waitpid()对它们进行状态收集，这些子进程的进程描述符仍然会留在系统中。这些子进程就成为僵尸进程。

### PCB（进程控制块）

PCB就是进程控制块，是操作系统中的一种数据结构，用于表示进程状态，操作系统通过PCB对进程进行管理。

PCB中包含有：进程标识符，处理器状态，进程调度信息，进程控制信息

**进程描述信息：** 

- 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 
- 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务； 

**进程控制和管理信息：** 

- 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 

**进程优先级：**

- 进程抢占 CPU 时的优先级； 

**资源分配清单：** 

- 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使用的 I/O 设备信息。 

**CPU 相关信息：** 

- CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程 重新执行时，能从断点处继续执行

###  进程的执行过程是什么样的，执行一个进程需要做哪些工作？

编译，链接和装入

### 进程的地址空间

> [(196条消息) linux 进程地址空间分布_xl365t-CSDN博客_linux进程地址空间分布](https://blog.csdn.net/u010318270/article/details/81058090?ops_request_misc=%7B%22request%5Fid%22%3A%22164644345016781683960510%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=164644345016781683960510&biz_id=0&spm=1018.2226.3001.4187)

在32位操作系统中，内存空间拥有4GB的寻址能力。操作系统会把高地址的空间分配给内核，称为内核空间。

**内核空间**

默认情况下，`Windows`将高地址的`2GB`空间分配给内核，`Linux`将高地址的`1GB`空间分配给内核。剩下的`2GB`或`3GB`的内存空间称为用户空间。在用户空间里，有许多地址区间有特殊的地位，一般来讲，应用程序使用的内存空间里有如下"默认"的区域。

**栈**

用于维护函数调用的上下文。栈通常在用户空间的最高地址处分配，通常有数兆字节的大小。（高地址向低增长）

**动态链接库映射区**：

用于映射装载的动态链接库，在linux中，如果可执行文件依赖于其他共享库，系统将在`0xbfxxxxxx`附近分配地址(kernel > 2.6) ，并将共享库载入到该空间。[kernel = 2.4x，从0x40000000开始分配]

**堆**：

用来容纳应用程序动态分配的内存区域，malloc或new分配内存时，得到的内存来自堆里。堆通常存在于栈的下方(低地址方向)，可以有几十或数百兆字节。（低地址向高增长）

**可执行文件映像**：

存储着可执行文件在内存里的映像，由装载器在装载时将可执行文件的内存读取或映射到这里。包括read/write sections和readonly sections。

**保留区**：

对内存中受到保护而禁止访问的内存区域的总称。

栈向低地址增长，堆向高地址增长。当栈或堆现有的大小不够用时，它将按照图中的增长方向扩大自身的尺寸，直到预留的空间被用完为止。

**往下是各种段（这里我从低向高说）**

- `.text`
  - 程序源代码编译后的机器指令放在代码段
- `.data`
  - 初始化且不为`0`的全局变量和局部静态变量放在数据段`.data`
- `.bss`
  - 未初始化的或者初始化为`0`的全局变量和局部静态变量要放在`.bss`段
  - 程序运行期间这个是要占内存的，所以我们的`.bss`段需要记录这些数据的大小，仅仅作为一个占用空间的标记，为未初始化的和初始化为`0`的全局变量和静态局部变量预留位置而已，并无内容。
- `.rodata`：
  - 只读数据段
  - 语义上支持了`C++`的`const`关键字；
  - 操作系统在加载时候可以将`.rodata`段的属性映射成只读，保证安全性
- `.comment`
  - 注释信息段
- `.note.GNU-stack`



![image-20220305092717270](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305092717270.png)

### 内核空间和用户空间

>  什么是内核呢？ 

计算机是由各种外部硬件设备组成的，⽐如内存、cpu、硬盘等，如果每个应用都要和这些硬件设备对接通信协议，那这样太累了，所以这个中间⼈就由内核来负责，让内核作为应用连接硬件设备的桥梁，应用程序只需关⼼与内核交互，不用关⼼硬件的细节

![image-20220305094935960](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305094935960.png)

**内核的功能**

- 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 
- 管理内存，决定内存的分配和回收，也就是内存管理的能力； 
- 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 
- 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与 操作系统之间的接口

**内核分区**

内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件，而应用程序具有的权限很小，因此大多数操作系统，把内存分成了两个区域： 

- 内核空间，这个内存空间只有内核程序可以访问； 
- 用户空间，这个内存空间专门给应用程序使用
- 用户空间的代码只能访问一个局部的内存空间，⽽内核空间的代码可以访问所有内存空间。
- 因此，当程序使用用户空间时，我们常说该程序在用户态执行，⽽当程序使内核空间时，程序则在内核态执行。

![image-20220305095325043](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220305095325043.png)

### 程序的运行

程序的运行的过程：程序的运行就变成一个进程，分为3步：

- 创建虚拟地址空间到物理内存的映射（创建内核地址映射结构体），创建页目录和页表
- 加载代码段和数据段（其他的段都不用，也不用段表、字符串段、debug段）。调试的时候需要debug段，必须把debug信息加载到内存上。
- 把可执行文件的入口地址写到CPU的PC寄存器里面（运行这个程序，CPU就知道运行这个可执行文件的第一条指令。在程序请求执行的时候，操作系统的加载器loader程序已经把文件的文件头里面的入口地址Entry point address是main函数第一行的地址放到cpu的PC寄存器里面。所以等到这个进程得到CPU资源的时候，CPU就知道从这个地址开始执行指令）

## 调度算法

### 进程调度算法

**先来先服务**

最简单的⼀个调度算法，就是⾮抢占式的先来先服务（First Come First Severd, FCFS）算法了

顾名思义，先来后到，每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻 塞，才会继续从队列中选择第⼀个进程接着运⾏。

这似乎很公平，但是当⼀个⻓作业先运⾏了，那么后⾯的短作业等待的时间就会很⻓，不利于短作业。 

FCFS 对⻓作业有利，适⽤于 CPU 繁忙型作业的系统，⽽不适⽤于 I/O 繁忙型作业的系统

**最短作业优先调度算法**

最短作业优先（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运⾏时间最短的进 程来运⾏，这有助于提⾼系统的吞吐量

这显然对⻓作业不利，很容易造成⼀种极端现象。 ⽐如，⼀个⻓作业在就绪队列等待运⾏，⽽这个就绪队列有⾮常多的短作业，那么就会使得⻓作业不断的 往后推，周转时间变⻓，致使⻓作业⻓期不会被运⾏。长作业被饿死

**高相应比优先调度算法**

前⾯的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和⻓作业。 

那么，⾼响应⽐优先 （Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和⻓作业。 

每次进⾏进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最⾼的进程投⼊运⾏，「响应 ⽐优先级」的计算公式

![image-20220326111646645](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220326111646645.png)

- 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应⽐」就越⾼，这样短作业的 进程容易被选中运⾏； 
- 如果两个进程「要求的服务时间」相同时，「等待时间」越⻓，「响应⽐」就越⾼，这就兼顾到了⻓ 作业进程，因为进程的响应⽐可以随时间等待的增加⽽提⾼，当其等待时间⾜够⻓时，其响应⽐便可 以升到很⾼，从⽽获得运⾏的机会；

**时间片轮转调度算法**

最古⽼、最简单、最公平且使⽤最⼴的算法就是时间⽚轮转（Round Robin, RR）调度算法

![image-20220326111818460](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220326111818460.png)

每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏。 

- 如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外⼀个进 程； 
- 如果该进程在时间⽚结束前阻塞或结束，则 CPU ⽴即进⾏切换；

另外，时间⽚的⻓度就是⼀个很关键的点

- 如果时间⽚设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率
- 如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓。

**最高优先级调度算法**



**多级反馈队列调度算法**

### 页面置换算法

**缺页中断**

当 CPU 访问的⻚⾯不在物理内存时，便会产⽣⼀个缺⻚中断，请求操作系统将所缺⻚调⼊到物理内存。那它与⼀般中断的主要区别在于：

- 缺⻚中断在指令执⾏「期间」产⽣和处理中断信号，⽽⼀般中断在⼀条指令执⾏「完成」后检查和处 理中断信号。 
- 缺⻚中断返回到该指令的开始重新执⾏「该指令」，⽽⼀般中断返回回到该指令的「下⼀个指令」执 ⾏。

**最佳页面置换算法**

最佳⻚⾯置换算法基本思路是，置换在「未来」最⻓时间不访问的⻚⾯

所以，该算法实现需要计算内存中每个逻辑⻚⾯的「下⼀次」访问时间，然后⽐较，选择未来最⻓时间不 访问的⻚⾯。 

我们举个例⼦，假设⼀开始有 3 个空闲的物理⻚，然后有请求的⻚⾯序列，那它的置换过程如下图

![image-20220326113524593](https://syz-picture.oss-cn-shenzhen.aliyuncs.com/image-20220326113524593.png)

这很理想，但是实际系统中⽆法实现，因为程序访问⻚⾯时是动态的，我们是⽆法预知每个⻚⾯在「下⼀ 次」访问前的等待时间。

所以，最佳⻚⾯置换算法作⽤是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明 你的算法是⾼效的。

**先进先出置换算法**

既然我们⽆法预知⻚⾯在下⼀次访问前所需的等待时间，那我们可以选择在内存驻留时间很⻓的⻚⾯进⾏ 中置换，这个就是「先进先出置换」算法的思想。

**最近最久未使用置换算法**

最近最久未使⽤（LRU）的置换算法的基本思路是，发⽣缺⻚时，选择最⻓时间没有被访问的⻚⾯进⾏置 换，也就是说，该算法假设已经很久没有使⽤的⻚⾯很有可能在未来较⻓的⼀段时间内仍然不会被使⽤。 

这种算法近似最优置换算法，最优置换算法是通过「未来」的使⽤情况来推测要淘汰的⻚⾯，⽽ LRU 则是 通过「历史」的使⽤情况来推测要淘汰的⻚⾯。

虽然 LRU 在理论上是可以实现的，但代价很⾼。为了完全实现 LRU，需要在内存中维护⼀个所有⻚⾯的链表，最近最多使⽤的⻚⾯在表头，最近最少使⽤的⻚⾯在表尾。

困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到⼀个⻚⾯，删除它，然后把它移 动到表头是⼀个⾮常费时的操作。 所以，LRU 虽然看上去不错，但是由于开销⽐较⼤，实际应⽤中⽐较少使⽤。

**时钟页面置换算法**

**最不常用置换算法**

### 磁盘调度算法

## 编译链接

### 程序运行

### 静态链接

### 动态链接



## 参考

- [(196条消息) C++学习第一节：深入编译链接和运行_孤傲小二~阿沐的博客-CSDN博客](https://rng-songbaobao.blog.csdn.net/article/details/90143576)
- 《图解系统》——小林coding（公众号）
- 《程序员的自我修养——装载，链接与库》
- 《现代操作系统》